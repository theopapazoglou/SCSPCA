SIMULATION 2: I.I.D. SCENARIO

def run_all_methods_analysis(data, n_splits=1, n_components_list=[2,3,4],
                            threshold=0.1, seed=1888):
    onp.random.seed(seed)
    Y = data[:, 0:1]
    X = data[:, 1:]
    p = X.shape[1]

    results = pd.DataFrame({
        'n_components': n_components_list,
        'mse_PCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_PCA': onp.zeros(len(n_components_list)),
        'mse_PLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_PLS': onp.zeros(len(n_components_list)),
        'mse_HSIC': onp.zeros(len(n_components_list)),
        'non_zero_vars_HSIC': onp.zeros(len(n_components_list)),
        'mse_Bair': onp.zeros(len(n_components_list)),
        'non_zero_vars_Bair': onp.zeros(len(n_components_list)),
        'mse_CSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_CSPCA': onp.zeros(len(n_components_list)),
        'mse_SCSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SCSPCA': onp.zeros(len(n_components_list)),
        'mse_SPLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPLS': onp.zeros(len(n_components_list)),
        'mse_SPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPCA': onp.zeros(len(n_components_list)),
        'mse_SSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SSPCA': onp.zeros(len(n_components_list)),
    })

    
    eta_sparse_grid = [2200, 2300, 2400, 2500, 2600, 2700]  
    eta_spls_grid = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]     
    para_spca_grid = [[0.01, 0.01, 0.01, 0.01], [0.05, 0.05, 0.05, 0.05], [0.1, 0.1, 0.1, 0.1], [1, 1, 1, 1]]  
    c_sspca_grid = [onp.sqrt(p)/20, onp.sqrt(p)/16, onp.sqrt(p)/8, onp.sqrt(p)/4, onp.sqrt(p)/2]         

    for i, n_components in enumerate(n_components_list):
        metrics = {key: [] for key in results.columns if key != 'n_components'}

        for _ in range(n_splits):
            X_train_val, X_test, Y_train_val, Y_test = train_test_split(
                X, Y, test_size=0.2, random_state=seed)
            X_train, X_val, Y_train, Y_val = train_test_split(
                X_train_val, Y_train_val, test_size=0.25, random_state=seed)  

            scaler_X = StandardScaler()
            X_train = scaler_X.fit_transform(X_train)
            X_val = scaler_X.transform(X_val)
            X_test = scaler_X.transform(X_test)
            scaler_Y = StandardScaler()
            Y_train = scaler_Y.fit_transform(Y_train)
            Y_val = scaler_Y.transform(Y_val)
            Y_test = scaler_Y.transform(Y_test)

            def count_nonzero_vars(W, threshold=1e-7):
                if W.ndim == 1:
                    W = W.reshape(-1, 1)
                return onp.mean(onp.sum(onp.abs(W) > threshold, axis=0))

            # PCA
            pca = PCA(n_components=n_components)
            X_train_pca = pca.fit_transform(X_train)
            X_val_pca = pca.transform(X_val)
            X_test_pca = pca.transform(X_test)
            lr = LinearRegression()
            lr.fit(X_train_pca, Y_train)
            Y_pred = lr.predict(X_test_pca)
            metrics['mse_PCA'].append(mean_squared_error(Y_test, Y_pred))
            metrics['non_zero_vars_PCA'].append(p)
            
            # PLS
            pls = PLSRegression(n_components=n_components)
            pls.fit(X_train, Y_train)
            Y_pred_pls = pls.predict(X_test)
            metrics['mse_PLS'].append(mean_squared_error(Y_test, Y_pred_pls))
            metrics['non_zero_vars_PLS'].append(p)

            # SPCA using HSIC
            sigma = 0.1
            K = rbf_kernel(Y_train, sigma)
            spca_result = spca_hsic(X_train, Y_train, K, n_components)
            W_hsic = spca_result['W']
            Z_train_hsic = X_train @ W_hsic
            Z_val_hsic = X_val @ W_hsic
            Z_test_hsic = X_test @ W_hsic
            lr_hsic = LinearRegression().fit(Z_train_hsic, Y_train)
            Y_pred_hsic = lr_hsic.predict(Z_test_hsic)
            metrics['mse_HSIC'].append(mean_squared_error(Y_test, Y_pred_hsic))
            metrics['non_zero_vars_HSIC'].append(count_nonzero_vars(W_hsic))

            # Bair's Method
            feature_scores = onp.abs(onp.corrcoef(X_train.T, Y_train.T)[:-1, -1])
            selected_features = feature_scores >= threshold
            X_train_selected = X_train[:, selected_features]
            X_val_selected = X_val[:, selected_features]
            X_test_selected = X_test[:, selected_features]
            pca_bair = PCA(n_components=min(n_components, X_train_selected.shape[1]))
            X_train_bair = pca_bair.fit_transform(X_train_selected)
            X_val_bair = pca_bair.transform(X_val_selected)
            X_test_bair = pca_bair.transform(X_test_selected)
            lr_bair = LinearRegression().fit(X_train_bair, Y_train)
            Y_pred_bair = lr_bair.predict(X_test_bair)
            metrics['mse_Bair'].append(mean_squared_error(Y_test, Y_pred_bair))
            metrics['non_zero_vars_Bair'].append(onp.sum(selected_features))

            # CSPCA
            lambda_grid = [0.01, 0.1, 1, 10, 100]
            best_lambda = lambda_grid[0]
            best_mse = float('inf')
            for lambda_ in lambda_grid:
                spca_sup = cspca(X_train, Y_train, n_components, lambda_=lambda_)
                W_cspca = spca_sup['W']
                Z_train_cspca = X_train @ W_cspca
                Z_val_cspca = X_val @ W_cspca
                lr_cspca = LinearRegression().fit(Z_train_cspca, Y_train)
                Y_pred_cspca = lr_cspca.predict(Z_val_cspca)
                current_mse = mean_squared_error(Y_val, Y_pred_cspca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_lambda = lambda_
            
            spca_sup = cspca(X_train, Y_train, n_components, lambda_=best_lambda)
            W_cspca = spca_sup['W']
            Z_train_cspca = X_train @ W_cspca
            Z_test_cspca = X_test @ W_cspca
            lr_cspca = LinearRegression().fit(Z_train_cspca, Y_train)
            Y_pred_cspca = lr_sup.predict(Z_test_cspca)
            metrics['mse_CSPCA'].append(mean_squared_error(Y_test, Y_pred_cspca))
            metrics['non_zero_vars_CSPCA'].append(count_nonzero_vars(W_cspca))
            
            # SCSPCA
            best_eta_sparse = eta_sparse_grid[0]
            best_mse = float('inf')
            for eta_sparse in eta_sparse_grid:
                kappa = 0.1
                C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
                W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                    C, n_components, p, eta_sparse * onp.ones(p))
                X_train_proj = X_train @ W_manpg
                X_val_proj = X_val @ W_manpg
                reg = LinearRegression()
                reg.fit(X_train_proj, Y_train)
                y_val_pred = reg.predict(X_val_proj)
                current_mse = mean_squared_error(Y_val, y_val_pred)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_sparse = eta_sparse
            
            print(f"Selected eta_sparse: {best_eta_sparse}")
            C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
            W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                C, n_components, p, best_eta_sparse * onp.ones(p))
            X_train_proj = X_train @ W_manpg
            X_test_proj = X_test @ W_manpg
            reg = LinearRegression()
            reg.fit(X_train_proj, Y_train)
            y_test_pred = reg.predict(X_test_proj)
            metrics['mse_SCSPCA'].append(mean_squared_error(Y_test, y_test_pred))
            metrics['non_zero_vars_SCSPCA'].append(count_nonzero_vars(W_manpg))

            # Sparse PLS (SPLS)
            best_eta_spls = eta_spls_grid[0]
            best_mse = float('inf')
            for eta_spls in eta_spls_grid:
                spls_result = spls(X_train, Y_train, K=n_components, 
                                  eta=eta_spls, kappa=0.2, 
                                  scale_x=False, scale_y=False)
                betahat = spls_result['betahat']
                Y_pred_spls = X_val @ betahat
                current_mse = mean_squared_error(Y_val, Y_pred_spls)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_spls = eta_spls
            
            print(f"Selected eta_spls: {best_eta_spls}")
            spls_result = spls(X_train, Y_train, K=n_components, 
                              eta=best_eta_spls, kappa=0.2, 
                              scale_x=False, scale_y=False)
            betahat = spls_result['betahat']
            Y_pred_spls = X_test @ betahat
            W_spls = spls_result['projection']
            if W_spls.shape[1] > n_components:
                W_spls = W_spls[:, :n_components]
            metrics['mse_SPLS'].append(mean_squared_error(Y_test, Y_pred_spls))
            metrics['non_zero_vars_SPLS'].append(count_nonzero_vars(W_spls))

            # Sparse PCA (SPCA)
            best_para_spca = para_spca_grid[0]
            best_mse = float('inf')
            for para_spca in para_spca_grid:
                spca_result = spca(X_train, K=n_components, 
                                 para=para_spca, 
                                 type_="predictor", sparse="penalty", lambda_=1e-4)
                W_spca = spca_result['loadings']
                Z_train_spca = X_train @ W_spca
                Z_val_spca = X_val @ W_spca
                lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
                Y_pred_spca = lr_spca.predict(Z_val_spca)
                current_mse = mean_squared_error(Y_val, Y_pred_spca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_para_spca = para_spca
            
            print(f"Selected para_spca: {best_para_spca}")
            spca_result = spca(X_train, K=n_components, 
                             para=best_para_spca, 
                             type_="predictor", sparse="penalty", lambda_=1e-4)
            W_spca = spca_result['loadings']
            Z_train_spca = X_train @ W_spca
            Z_test_spca = X_test @ W_spca
            lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
            Y_pred_spca = lr_spca.predict(Z_test_spca)
            metrics['mse_SPCA'].append(mean_squared_error(Y_test, Y_pred_spca))
            metrics['non_zero_vars_SPCA'].append(count_nonzero_vars(W_spca))

            # Sparse Supervised PCA
            best_c_sspca = c_sspca_grid[0]
            best_mse = float('inf')
            for c_sspca in c_sspca_grid:
                sspca_result = sspca(X_train, Y_train, K=n_components, c=c_sspca, 
                                   X_test=X_val, Y_test=Y_val, kernel_type='rbf', sigma=0.1)
                Z_train_sspca = sspca_result['Z']
                Z_val_sspca = sspca_result['Z_test']
                reg = LinearRegression().fit(Z_train_sspca, Y_train)
                Y_pred_sspca = reg.predict(Z_val_sspca)
                current_mse = mean_squared_error(Y_val, Y_pred_sspca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_c_sspca = c_sspca
            
            print(f"Selected c_sspca: {best_c_sspca}")
            sspca_result = sspca(X_train, Y_train, K=n_components, c=best_c_sspca, 
                               X_test=X_test, Y_test=Y_test, kernel_type='rbf', sigma=0.1)
            Z_train_sspca = sspca_result['Z']
            Z_test_sspca = sspca_result['Z_test']
            W_sspca = sspca_result['V']
            reg = LinearRegression().fit(Z_train_sspca, Y_train)
            Y_pred_sspca = reg.predict(Z_test_sspca)
            metrics['mse_SSPCA'].append(mean_squared_error(Y_test, Y_pred_sspca))
            metrics['non_zero_vars_SSPCA'].append(count_nonzero_vars(W_sspca))
            
        for key in metrics:
            results.loc[i, key] = onp.mean(metrics[key])

    return results

def run_simulation_B(n_datasets=20, n=100, p=500, n_splits=1, n_components_list=[2]):
    methods = ['PCA', 'PLS', 'HSIC', 'Bair', 'CSPCA', 'SCSPCA', 'SPLS', 'SPCA', 'SSPCA']
    results = {method: {
        'MSE': onp.zeros((n_datasets, len(n_components_list))),
        'NonZeroVars': onp.zeros((n_datasets, len(n_components_list)))
    } for method in methods}

    for i in range(n_datasets):
        onp.random.seed(123 + i)
        X = onp.random.normal(size=(n, p))
        X_informative = X[:, :4]
        X1 = X_informative[:, 0]
        X2 = X_informative[:, 1]
        X3 = X_informative[:, 2]
        X4 = X_informative[:, 3]
        error = onp.random.normal(0, 0.1, n)
        Y = onp.exp(X1) + 4 * onp.sin(X2) - 3 * X3 + X4 * error
        data_B = onp.column_stack((Y[:, onp.newaxis], X))


        res = run_all_methods_analysis(data_B, n_splits=n_splits, n_components_list=n_components_list)

        for method in methods:
            results[method]['MSE'][i] = res[f'mse_{method}']
            results[method]['NonZeroVars'][i] = res[f'non_zero_vars_{method}']
            
    def compute_stats(metric_matrix):
        avg = onp.nanmean(metric_matrix, axis=0)
        std_err = onp.nanstd(metric_matrix, axis=0) / onp.sqrt(n_datasets)
        return {'avg': avg, 'std_err': std_err}

    stats = {method: {
        'MSE': compute_stats(results[method]['MSE']),
        'NonZeroVars': compute_stats(results[method]['NonZeroVars'])
    } for method in methods}

    print("\nSimulation B (Non-Linear: Y = e^X1 + 4sin(X2) - 3X3 + X4*epsilon):")
    for method in methods:
        print(f"  {method}:")
        print("    MSE:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['MSE']['avg'][j]
            se = stats[method]['MSE']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.4f} ± {se:.4f}")
        print("    Non-zero variables:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['NonZeroVars']['avg'][j]
            se = stats[method]['NonZeroVars']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.1f} ± {se:.1f}")

    return {'stats': stats, 'raw_results': results}

onp.random.seed(29518)
results_B = run_simulation_B(n_datasets=20, n=100, p=500, n_splits=1, n_components_list=[2,3,4])


SIMULATION 2: CORRELATED SCENARIO

def run_all_methods_analysis(data, n_splits=1, n_components_list=[2,3,4],
                            threshold=0.1, seed=1888):
    onp.random.seed(seed)
    Y = data[:, 0:1]
    X = data[:, 1:]
    p = X.shape[1]

    results = pd.DataFrame({
        'n_components': n_components_list,
        'mse_PCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_PCA': onp.zeros(len(n_components_list)),
        'mse_PLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_PLS': onp.zeros(len(n_components_list)),
        'mse_HSIC': onp.zeros(len(n_components_list)),
        'non_zero_vars_HSIC': onp.zeros(len(n_components_list)),
        'mse_Bair': onp.zeros(len(n_components_list)),
        'non_zero_vars_Bair': onp.zeros(len(n_components_list)),
        'mse_CSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_CSPCA': onp.zeros(len(n_components_list)),
        'mse_SCSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SCSPCA': onp.zeros(len(n_components_list)),
        'mse_SPLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPLS': onp.zeros(len(n_components_list)),
        'mse_SPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPCA': onp.zeros(len(n_components_list)),
        'mse_SSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SSPCA': onp.zeros(len(n_components_list)),
    })

    
    eta_sparse_grid = [2200, 2300, 2400, 2500, 2600, 2700]  
    eta_spls_grid = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]     
    para_spca_grid = [[0.01, 0.01, 0.01, 0.01], [0.05, 0.05, 0.05, 0.05], [0.1, 0.1, 0.1, 0.1], [1, 1, 1, 1]]  
    c_sspca_grid = [onp.sqrt(p)/20, onp.sqrt(p)/16, onp.sqrt(p)/8, onp.sqrt(p)/4, onp.sqrt(p)/2]         

    for i, n_components in enumerate(n_components_list):
        metrics = {key: [] for key in results.columns if key != 'n_components'}

        for _ in range(n_splits):
            X_train_val, X_test, Y_train_val, Y_test = train_test_split(
                X, Y, test_size=0.2, random_state=seed)
            X_train, X_val, Y_train, Y_val = train_test_split(
                X_train_val, Y_train_val, test_size=0.25, random_state=seed)  

            scaler_X = StandardScaler()
            X_train = scaler_X.fit_transform(X_train)
            X_val = scaler_X.transform(X_val)
            X_test = scaler_X.transform(X_test)
            scaler_Y = StandardScaler()
            Y_train = scaler_Y.fit_transform(Y_train)
            Y_val = scaler_Y.transform(Y_val)
            Y_test = scaler_Y.transform(Y_test)

            def count_nonzero_vars(W, threshold=1e-7):
                if W.ndim == 1:
                    W = W.reshape(-1, 1)
                return onp.mean(onp.sum(onp.abs(W) > threshold, axis=0))

            # PCA
            pca = PCA(n_components=n_components)
            X_train_pca = pca.fit_transform(X_train)
            X_val_pca = pca.transform(X_val)
            X_test_pca = pca.transform(X_test)
            lr = LinearRegression()
            lr.fit(X_train_pca, Y_train)
            Y_pred = lr.predict(X_test_pca)
            metrics['mse_PCA'].append(mean_squared_error(Y_test, Y_pred))
            metrics['non_zero_vars_PCA'].append(p)
            
            # PLS
            pls = PLSRegression(n_components=n_components)
            pls.fit(X_train, Y_train)
            Y_pred_pls = pls.predict(X_test)
            metrics['mse_PLS'].append(mean_squared_error(Y_test, Y_pred_pls))
            metrics['non_zero_vars_PLS'].append(p)

            # SPCA using HSIC
            sigma = 0.1
            K = rbf_kernel(Y_train, sigma)
            spca_result = spca_hsic(X_train, Y_train, K, n_components)
            W_hsic = spca_result['W']
            Z_train_hsic = X_train @ W_hsic
            Z_val_hsic = X_val @ W_hsic
            Z_test_hsic = X_test @ W_hsic
            lr_hsic = LinearRegression().fit(Z_train_hsic, Y_train)
            Y_pred_hsic = lr_hsic.predict(Z_test_hsic)
            metrics['mse_HSIC'].append(mean_squared_error(Y_test, Y_pred_hsic))
            metrics['non_zero_vars_HSIC'].append(count_nonzero_vars(W_hsic))

            # Bair's Method
            feature_scores = onp.abs(onp.corrcoef(X_train.T, Y_train.T)[:-1, -1])
            selected_features = feature_scores >= threshold
            X_train_selected = X_train[:, selected_features]
            X_val_selected = X_val[:, selected_features]
            X_test_selected = X_test[:, selected_features]
            pca_bair = PCA(n_components=min(n_components, X_train_selected.shape[1]))
            X_train_bair = pca_bair.fit_transform(X_train_selected)
            X_val_bair = pca_bair.transform(X_val_selected)
            X_test_bair = pca_bair.transform(X_test_selected)
            lr_bair = LinearRegression().fit(X_train_bair, Y_train)
            Y_pred_bair = lr_bair.predict(X_test_bair)
            metrics['mse_Bair'].append(mean_squared_error(Y_test, Y_pred_bair))
            metrics['non_zero_vars_Bair'].append(onp.sum(selected_features))

            # CSPCA
            lambda_grid = [0.01, 0.1, 1]
            best_lambda = lambda_grid[0]
            best_mse = float('inf')
            for lambda_ in lambda_grid:
                spca_sup = cspca(X_train, Y_train, n_components, lambda_=lambda_)
                W_sup = spca_sup['W']
                Z_train_sup = X_train @ W_sup
                Z_val_sup = X_val @ W_sup
                lr_sup = LinearRegression().fit(Z_train_sup, Y_train)
                Y_pred_sup = lr_sup.predict(Z_val_sup)
                current_mse = mean_squared_error(Y_val, Y_pred_sup)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_lambda = lambda_
            
            spca_sup = cspca(X_train, Y_train, n_components, lambda_=best_lambda)
            W_sup = spca_sup['W']
            Z_train_sup = X_train @ W_sup
            Z_test_sup = X_test @ W_sup
            lr_sup = LinearRegression().fit(Z_train_sup, Y_train)
            Y_pred_sup = lr_sup.predict(Z_test_sup)
            metrics['mse_CSPCA'].append(mean_squared_error(Y_test, Y_pred_sup))
            metrics['non_zero_vars_CSPCA'].append(count_nonzero_vars(W_sup))
            
            # SCSPCA
            best_eta_sparse = eta_sparse_grid[0]
            best_mse = float('inf')
            for eta_sparse in eta_sparse_grid:
                kappa = 0.1
                C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
                W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                    C, n_components, p, eta_sparse * onp.ones(p))
                X_train_proj = X_train @ W_manpg
                X_val_proj = X_val @ W_manpg
                reg = LinearRegression()
                reg.fit(X_train_proj, Y_train)
                y_val_pred = reg.predict(X_val_proj)
                current_mse = mean_squared_error(Y_val, y_val_pred)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_sparse = eta_sparse
            
            print(f"Selected eta_sparse: {best_eta_sparse}")
            C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
            W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                C, n_components, p, best_eta_sparse * onp.ones(p))
            X_train_proj = X_train @ W_manpg
            X_test_proj = X_test @ W_manpg
            reg = LinearRegression()
            reg.fit(X_train_proj, Y_train)
            y_test_pred = reg.predict(X_test_proj)
            metrics['mse_SCSPCA'].append(mean_squared_error(Y_test, y_test_pred))
            metrics['non_zero_vars_SCSPCA'].append(count_nonzero_vars(W_manpg))

            # Sparse PLS (SPLS)
            best_eta_spls = eta_spls_grid[0]
            best_mse = float('inf')
            for eta_spls in eta_spls_grid:
                spls_result = spls(X_train, Y_train, K=n_components, 
                                  eta=eta_spls, kappa=0.2, 
                                  scale_x=False, scale_y=False)
                betahat = spls_result['betahat']
                Y_pred_spls = X_val @ betahat
                current_mse = mean_squared_error(Y_val, Y_pred_spls)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_spls = eta_spls
            
            print(f"Selected eta_spls: {best_eta_spls}")
            spls_result = spls(X_train, Y_train, K=n_components, 
                              eta=best_eta_spls, kappa=0.2, 
                              scale_x=False, scale_y=False)
            betahat = spls_result['betahat']
            Y_pred_spls = X_test @ betahat
            W_spls = spls_result['projection']
            if W_spls.shape[1] > n_components:
                W_spls = W_spls[:, :n_components]
            metrics['mse_SPLS'].append(mean_squared_error(Y_test, Y_pred_spls))
            metrics['non_zero_vars_SPLS'].append(count_nonzero_vars(W_spls))

            # Sparse PCA (SPCA)
            best_para_spca = para_spca_grid[0]
            best_mse = float('inf')
            for para_spca in para_spca_grid:
                spca_result = spca(X_train, K=n_components, 
                                 para=para_spca, 
                                 type_="predictor", sparse="penalty", lambda_=1e-4)
                W_spca = spca_result['loadings']
                Z_train_spca = X_train @ W_spca
                Z_val_spca = X_val @ W_spca
                lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
                Y_pred_spca = lr_spca.predict(Z_val_spca)
                current_mse = mean_squared_error(Y_val, Y_pred_spca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_para_spca = para_spca
            
            print(f"Selected para_spca: {best_para_spca}")
            spca_result = spca(X_train, K=n_components, 
                             para=best_para_spca, 
                             type_="predictor", sparse="penalty", lambda_=1e-4)
            W_spca = spca_result['loadings']
            Z_train_spca = X_train @ W_spca
            Z_test_spca = X_test @ W_spca
            lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
            Y_pred_spca = lr_spca.predict(Z_test_spca)
            metrics['mse_SPCA'].append(mean_squared_error(Y_test, Y_pred_spca))
            metrics['non_zero_vars_SPCA'].append(count_nonzero_vars(W_spca))

            # Sparse Supervised PCA
            best_c_sspca = c_sspca_grid[0]
            best_mse = float('inf')
            for c_sspca in c_sspca_grid:
                sspca_result = sspca(X_train, Y_train, K=n_components, c=c_sspca, 
                                   X_test=X_val, Y_test=Y_val, kernel_type='rbf', sigma=0.1)
                Z_train_sspca = sspca_result['Z']
                Z_val_sspca = sspca_result['Z_test']
                reg = LinearRegression().fit(Z_train_sspca, Y_train)
                Y_pred_sspca = reg.predict(Z_val_sspca)
                current_mse = mean_squared_error(Y_val, Y_pred_sspca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_c_sspca = c_sspca
            
            print(f"Selected c_sspca: {best_c_sspca}")
            sspca_result = sspca(X_train, Y_train, K=n_components, c=best_c_sspca, 
                               X_test=X_test, Y_test=Y_test, kernel_type='rbf', sigma=0.1)
            Z_train_sspca = sspca_result['Z']
            Z_test_sspca = sspca_result['Z_test']
            W_sspca = sspca_result['V']
            reg = LinearRegression().fit(Z_train_sspca, Y_train)
            Y_pred_sspca = reg.predict(Z_test_sspca)
            metrics['mse_SSPCA'].append(mean_squared_error(Y_test, Y_pred_sspca))
            metrics['non_zero_vars_SSPCA'].append(count_nonzero_vars(W_sspca))
            
        for key in metrics:
            results.loc[i, key] = onp.mean(metrics[key])

    return results

def run_simulation_B(n_datasets=5, n=100, p=500, n_splits=1, n_components_list=[2,3,4]):
    methods = ['PCR', 'PLS', 'HSIC', 'Bair', 'CSPCA', 'SCSPCA', 'SPLS', 'SPCA', 'SSPCA']
    results = {method: {
        'MSE': onp.zeros((n_datasets, len(n_components_list))),
        'NonZeroVars': onp.zeros((n_datasets, len(n_components_list)))
    } for method in methods}

    for i in range(n_datasets):
        onp.random.seed(123 + i)
        cov_matrix = create_toeplitz_cov(p, rho)
        X = onp.random.multivariate_normal(mean=onp.zeros(p), cov=cov_matrix, size=n)
        X_informative = X[:, :4]
        X1 = X_informative[:, 0]
        X2 = X_informative[:, 1]
        X3 = X_informative[:, 2]
        X4 = X_informative[:, 3]
        error = onp.random.normal(0, 0.1, n)
        Y = onp.exp(X1) + 4 * onp.sin(X2) - 3 * X3 + X4 * error
        data_B = onp.column_stack((Y[:, onp.newaxis], X))


        res = run_all_methods_analysis(data_B, n_splits=n_splits, n_components_list=n_components_list)

        for method in methods:
            results[method]['MSE'][i] = res[f'mse_{method}']
            results[method]['NonZeroVars'][i] = res[f'non_zero_vars_{method}']
            
    def compute_stats(metric_matrix):
        avg = onp.nanmean(metric_matrix, axis=0)
        std_err = onp.nanstd(metric_matrix, axis=0) / onp.sqrt(n_datasets)
        return {'avg': avg, 'std_err': std_err}

    stats = {method: {
        'MSE': compute_stats(results[method]['MSE']),
        'NonZeroVars': compute_stats(results[method]['NonZeroVars'])
    } for method in methods}

    print("\nSimulation B (Non-Linear: Y = e^X1 + 4sin(X2) - 3X3 + X4*epsilon):")
    for method in methods:
        print(f"  {method}:")
        print("    MSE:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['MSE']['avg'][j]
            se = stats[method]['MSE']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.4f} ± {se:.4f}")
        print("    Non-zero variables:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['NonZeroVars']['avg'][j]
            se = stats[method]['NonZeroVars']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.1f} ± {se:.1f}")

    return {'stats': stats, 'raw_results': results}

onp.random.seed(29518)
results_B = run_simulation_B(n_datasets=20, n=100, p=500, n_splits=1, n_components_list=[2,3,4])


SIMULATION 3: I.I.D. SCENARIO

def run_all_methods_analysis(data, n_splits=1, n_components_list=[2,3,4],
                            threshold=0.1, seed=2002):
    onp.random.seed(seed)
    Y = data[:, 0:1]
    X = data[:, 1:]
    p = X.shape[1]

    results = pd.DataFrame({
        'n_components': n_components_list,
        'mse_PCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_PCA': onp.zeros(len(n_components_list)),
        'mse_PLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_PLS': onp.zeros(len(n_components_list)),
        'mse_HSIC': onp.zeros(len(n_components_list)),
        'non_zero_vars_HSIC': onp.zeros(len(n_components_list)),
        'mse_Bair': onp.zeros(len(n_components_list)),
        'non_zero_vars_Bair': onp.zeros(len(n_components_list)),
        'mse_CSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_CSPCA': onp.zeros(len(n_components_list)),
        'mse_SCSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SCSPCA': onp.zeros(len(n_components_list)),
        'mse_SPLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPLS': onp.zeros(len(n_components_list)),
        'mse_SPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPCA': onp.zeros(len(n_components_list)),
        'mse_SSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SSPCA': onp.zeros(len(n_components_list)),
    })

    
    eta_sparse_grid = [1500, 2000, 2200, 2300, 2400, 2500, 2550]  
    eta_spls_grid = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]     
    para_spca_grid = [[0.01, 0.01, 0.01, 0.01], [0.05, 0.05, 0.05, 0.05], [0.1, 0.1, 0.1, 0.1], [1, 1, 1, 1]]  
    c_sspca_grid = [onp.sqrt(p)/20, onp.sqrt(p)/16, onp.sqrt(p)/8, onp.sqrt(p)/4, onp.sqrt(p)/2]         

    for i, n_components in enumerate(n_components_list):
        metrics = {key: [] for key in results.columns if key != 'n_components'}

        for _ in range(n_splits):
            X_train_val, X_test, Y_train_val, Y_test = train_test_split(
                X, Y, test_size=0.2, random_state=seed)
            X_train, X_val, Y_train, Y_val = train_test_split(
                X_train_val, Y_train_val, test_size=0.25, random_state=seed)  

            scaler_X = StandardScaler()
            X_train = scaler_X.fit_transform(X_train)
            X_val = scaler_X.transform(X_val)
            X_test = scaler_X.transform(X_test)
            scaler_Y = StandardScaler()
            Y_train = scaler_Y.fit_transform(Y_train)
            Y_val = scaler_Y.transform(Y_val)
            Y_test = scaler_Y.transform(Y_test)

            def count_nonzero_vars(W, threshold=1e-7):
                if W.ndim == 1:
                    W = W.reshape(-1, 1)
                return onp.mean(onp.sum(onp.abs(W) > threshold, axis=0))

            # PCA
            pca = PCA(n_components=n_components)
            X_train_pca = pca.fit_transform(X_train)
            X_val_pca = pca.transform(X_val)
            X_test_pca = pca.transform(X_test)
            lr = LinearRegression()
            lr.fit(X_train_pca, Y_train)
            Y_pred = lr.predict(X_test_pca)
            metrics['mse_PCA'].append(mean_squared_error(Y_test, Y_pred))
            metrics['non_zero_vars_PCA'].append(p)
            
            # PLS
            pls = PLSRegression(n_components=n_components)
            pls.fit(X_train, Y_train)
            Y_pred_pls = pls.predict(X_test)
            metrics['mse_PLS'].append(mean_squared_error(Y_test, Y_pred_pls))
            metrics['non_zero_vars_PLS'].append(p)

            # SPCA using HSIC
            sigma = 0.1
            K = rbf_kernel(Y_train, sigma)
            spca_result = spca_hsic(X_train, Y_train, K, n_components)
            W_hsic = spca_result['W']
            Z_train_hsic = X_train @ W_hsic
            Z_val_hsic = X_val @ W_hsic
            Z_test_hsic = X_test @ W_hsic
            lr_hsic = LinearRegression().fit(Z_train_hsic, Y_train)
            Y_pred_hsic = lr_hsic.predict(Z_test_hsic)
            metrics['mse_HSIC'].append(mean_squared_error(Y_test, Y_pred_hsic))
            metrics['non_zero_vars_HSIC'].append(count_nonzero_vars(W_hsic))

            # Bair's Method
            feature_scores = onp.abs(onp.corrcoef(X_train.T, Y_train.T)[:-1, -1])
            selected_features = feature_scores >= threshold
            X_train_selected = X_train[:, selected_features]
            X_val_selected = X_val[:, selected_features]
            X_test_selected = X_test[:, selected_features]
            pca_bair = PCA(n_components=min(n_components, X_train_selected.shape[1]))
            X_train_bair = pca_bair.fit_transform(X_train_selected)
            X_val_bair = pca_bair.transform(X_val_selected)
            X_test_bair = pca_bair.transform(X_test_selected)
            lr_bair = LinearRegression().fit(X_train_bair, Y_train)
            Y_pred_bair = lr_bair.predict(X_test_bair)
            metrics['mse_Bair'].append(mean_squared_error(Y_test, Y_pred_bair))
            metrics['non_zero_vars_Bair'].append(onp.sum(selected_features))

            # CSPCA
            lambda_grid = [0.01, 0.1, 1, 10, 100]
            best_lambda = lambda_grid[0]
            best_mse = float('inf')
            for lambda_ in lambda_grid:
                spca_sup = cspca(X_train, Y_train, n_components, lambda_=lambda_)
                W_cspca = spca_sup['W']
                Z_train_cspca = X_train @ W_cspca
                Z_val_cspca = X_val @ W_cspca
                lr_cspca = LinearRegression().fit(Z_train_cspca, Y_train)
                Y_pred_cspca = lr_cspca.predict(Z_val_cspca)
                current_mse = mean_squared_error(Y_val, Y_pred_cspca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_lambda = lambda_
            
            spca_sup = cspca(X_train, Y_train, n_components, lambda_=best_lambda)
            W_cspca = spca_sup['W']
            Z_train_cspca = X_train @ W_cspca
            Z_test_cspca = X_test @ W_cspca
            lr_cspca = LinearRegression().fit(Z_train_cspca, Y_train)
            Y_pred_cspca = lr_sup.predict(Z_test_cspca)
            metrics['mse_CSPCA'].append(mean_squared_error(Y_test, Y_pred_cspca))
            metrics['non_zero_vars_CSPCA'].append(count_nonzero_vars(W_cspca))
            
            # SCSPCA
            best_eta_sparse = eta_sparse_grid[0]
            best_mse = float('inf')
            for eta_sparse in eta_sparse_grid:
                kappa = 0.1
                C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
                W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                    C, n_components, p, eta_sparse * onp.ones(p))
                X_train_proj = X_train @ W_manpg
                X_val_proj = X_val @ W_manpg
                reg = LinearRegression()
                reg.fit(X_train_proj, Y_train)
                y_val_pred = reg.predict(X_val_proj)
                current_mse = mean_squared_error(Y_val, y_val_pred)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_sparse = eta_sparse
            
            print(f"Selected eta_sparse: {best_eta_sparse}")
            C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
            W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                C, n_components, p, best_eta_sparse * onp.ones(p))
            X_train_proj = X_train @ W_manpg
            X_test_proj = X_test @ W_manpg
            reg = LinearRegression()
            reg.fit(X_train_proj, Y_train)
            y_test_pred = reg.predict(X_test_proj)
            metrics['mse_SCSPCA'].append(mean_squared_error(Y_test, y_test_pred))
            metrics['non_zero_vars_SCSPCA'].append(count_nonzero_vars(W_manpg))

            # Sparse PLS (SPLS)
            best_eta_spls = eta_spls_grid[0]
            best_mse = float('inf')
            for eta_spls in eta_spls_grid:
                spls_result = spls(X_train, Y_train, K=n_components, 
                                  eta=eta_spls, kappa=0.2, 
                                  scale_x=False, scale_y=False)
                betahat = spls_result['betahat']
                Y_pred_spls = X_val @ betahat
                current_mse = mean_squared_error(Y_val, Y_pred_spls)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_spls = eta_spls
            
            print(f"Selected eta_spls: {best_eta_spls}")
            spls_result = spls(X_train, Y_train, K=n_components, 
                              eta=best_eta_spls, kappa=0.2, 
                              scale_x=False, scale_y=False)
            betahat = spls_result['betahat']
            Y_pred_spls = X_test @ betahat
            W_spls = spls_result['projection']
            if W_spls.shape[1] > n_components:
                W_spls = W_spls[:, :n_components]
            metrics['mse_SPLS'].append(mean_squared_error(Y_test, Y_pred_spls))
            metrics['non_zero_vars_SPLS'].append(count_nonzero_vars(W_spls))

            # Sparse PCA (SPCA)
            best_para_spca = para_spca_grid[0]
            best_mse = float('inf')
            for para_spca in para_spca_grid:
                spca_result = spca(X_train, K=n_components, 
                                 para=para_spca, 
                                 type_="predictor", sparse="penalty", lambda_=1e-4)
                W_spca = spca_result['loadings']
                Z_train_spca = X_train @ W_spca
                Z_val_spca = X_val @ W_spca
                lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
                Y_pred_spca = lr_spca.predict(Z_val_spca)
                current_mse = mean_squared_error(Y_val, Y_pred_spca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_para_spca = para_spca
            
            print(f"Selected para_spca: {best_para_spca}")
            spca_result = spca(X_train, K=n_components, 
                             para=best_para_spca, 
                             type_="predictor", sparse="penalty", lambda_=1e-4)
            W_spca = spca_result['loadings']
            Z_train_spca = X_train @ W_spca
            Z_test_spca = X_test @ W_spca
            lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
            Y_pred_spca = lr_spca.predict(Z_test_spca)
            metrics['mse_SPCA'].append(mean_squared_error(Y_test, Y_pred_spca))
            metrics['non_zero_vars_SPCA'].append(count_nonzero_vars(W_spca))

            # Sparse Supervised PCA
            best_c_sspca = c_sspca_grid[0]
            best_mse = float('inf')
            for c_sspca in c_sspca_grid:
                sspca_result = sspca(X_train, Y_train, K=n_components, c=c_sspca, 
                                   X_test=X_val, Y_test=Y_val, kernel_type='rbf', sigma=0.1)
                Z_train_sspca = sspca_result['Z']
                Z_val_sspca = sspca_result['Z_test']
                reg = LinearRegression().fit(Z_train_sspca, Y_train)
                Y_pred_sspca = reg.predict(Z_val_sspca)
                current_mse = mean_squared_error(Y_val, Y_pred_sspca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_c_sspca = c_sspca
            
            print(f"Selected c_sspca: {best_c_sspca}")
            sspca_result = sspca(X_train, Y_train, K=n_components, c=best_c_sspca, 
                               X_test=X_test, Y_test=Y_test, kernel_type='rbf', sigma=0.1)
            Z_train_sspca = sspca_result['Z']
            Z_test_sspca = sspca_result['Z_test']
            W_sspca = sspca_result['V']
            reg = LinearRegression().fit(Z_train_sspca, Y_train)
            Y_pred_sspca = reg.predict(Z_test_sspca)
            metrics['mse_SSPCA'].append(mean_squared_error(Y_test, Y_pred_sspca))
            metrics['non_zero_vars_SSPCA'].append(count_nonzero_vars(W_sspca))
            
        for key in metrics:
            results.loc[i, key] = onp.mean(metrics[key])

    return results

def run_simulation_C(n_datasets=20, n=100, p=500, n_splits=1, n_components_list=[2,3,4]):
    methods = ['PCA', 'PLS', 'HSIC', 'Bair', 'CSPCA', 'SCSPCA', 'SPLS', 'SPCA', 'SSPCA']
    results = {method: {
        'MSE': onp.zeros((n_datasets, len(n_components_list))),
        'NonZeroVars': onp.zeros((n_datasets, len(n_components_list)))
    } for method in methods}

    for i in range(n_datasets):
        onp.random.seed(123 + i)
        X = onp.random.normal(size=(n, p))
        X_informative = X[:, :4]
        X1 = X_informative[:, 0]
        X2 = X_informative[:, 1]
        X3 = X_informative[:, 2]
        X4 = X_informative[:, 3]
        error = onp.random.normal(0, 0.1, n)
        Y = X1 ** 2 + 3 * onp.sin(X2) - onp.exp(X3 + 1) + 1/(1+X4) + error
        data_C = onp.column_stack((Y[:, onp.newaxis], X))


        res = run_all_methods_analysis(data_C, n_splits=n_splits, n_components_list=n_components_list)

        for method in methods:
            results[method]['MSE'][i] = res[f'mse_{method}']
            results[method]['NonZeroVars'][i] = res[f'non_zero_vars_{method}']
            
    def compute_stats(metric_matrix):
        avg = onp.nanmean(metric_matrix, axis=0)
        std_err = onp.nanstd(metric_matrix, axis=0) / onp.sqrt(n_datasets)
        return {'avg': avg, 'std_err': std_err}

    stats = {method: {
        'MSE': compute_stats(results[method]['MSE']),
        'NonZeroVars': compute_stats(results[method]['NonZeroVars'])
    } for method in methods}

    print("\nSimulation C (Non-Linear: Y = X1^2 + 3sin(X2) - e^(X3+1) + 1/(1+X4) + epsilon):")
    for method in methods:
        print(f"  {method}:")
        print("    MSE:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['MSE']['avg'][j]
            se = stats[method]['MSE']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.4f} ± {se:.4f}")
        print("    Non-zero variables:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['NonZeroVars']['avg'][j]
            se = stats[method]['NonZeroVars']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.1f} ± {se:.1f}")

    return {'stats': stats, 'raw_results': results}

onp.random.seed(219746)
results_C = run_simulation_C(n_datasets=20, n=100, p=500, n_splits=1, n_components_list=[2,3,4])


SIMULATION 3: CORRELATED SCENARIO

def run_all_methods_analysis(data, n_splits=1, n_components_list=[2,3,4],
                            threshold=0.1, seed=2002):
    onp.random.seed(seed)
    Y = data[:, 0:1]
    X = data[:, 1:]
    p = X.shape[1]

    results = pd.DataFrame({
        'n_components': n_components_list,
        'mse_PCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_PCA': onp.zeros(len(n_components_list)),
        'mse_PLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_PLS': onp.zeros(len(n_components_list)),
        'mse_HSIC': onp.zeros(len(n_components_list)),
        'non_zero_vars_HSIC': onp.zeros(len(n_components_list)),
        'mse_Bair': onp.zeros(len(n_components_list)),
        'non_zero_vars_Bair': onp.zeros(len(n_components_list)),
        'mse_CSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_CSPCA': onp.zeros(len(n_components_list)),
        'mse_SCSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SCSPCA': onp.zeros(len(n_components_list)),
        'mse_SPLS': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPLS': onp.zeros(len(n_components_list)),
        'mse_SPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SPCA': onp.zeros(len(n_components_list)),
        'mse_SSPCA': onp.zeros(len(n_components_list)),
        'non_zero_vars_SSPCA': onp.zeros(len(n_components_list)),
    })

    
    eta_sparse_grid = [1500, 2000, 2200, 2300, 2400, 2500, 2550]  
    eta_spls_grid = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]     
    para_spca_grid = [[0.01, 0.01, 0.01, 0.01], [0.05, 0.05, 0.05, 0.05], [0.1, 0.1, 0.1, 0.1], [1, 1, 1, 1]]  
    c_sspca_grid = [onp.sqrt(p)/20, onp.sqrt(p)/16, onp.sqrt(p)/8, onp.sqrt(p)/4, onp.sqrt(p)/2]         

    for i, n_components in enumerate(n_components_list):
        metrics = {key: [] for key in results.columns if key != 'n_components'}

        for _ in range(n_splits):
            X_train_val, X_test, Y_train_val, Y_test = train_test_split(
                X, Y, test_size=0.2, random_state=seed)
            X_train, X_val, Y_train, Y_val = train_test_split(
                X_train_val, Y_train_val, test_size=0.25, random_state=seed)  

            scaler_X = StandardScaler()
            X_train = scaler_X.fit_transform(X_train)
            X_val = scaler_X.transform(X_val)
            X_test = scaler_X.transform(X_test)
            scaler_Y = StandardScaler()
            Y_train = scaler_Y.fit_transform(Y_train)
            Y_val = scaler_Y.transform(Y_val)
            Y_test = scaler_Y.transform(Y_test)

            def count_nonzero_vars(W, threshold=1e-7):
                if W.ndim == 1:
                    W = W.reshape(-1, 1)
                return onp.mean(onp.sum(onp.abs(W) > threshold, axis=0))

            # PCA
            pca = PCA(n_components=n_components)
            X_train_pca = pca.fit_transform(X_train)
            X_val_pca = pca.transform(X_val)
            X_test_pca = pca.transform(X_test)
            lr = LinearRegression()
            lr.fit(X_train_pca, Y_train)
            Y_pred = lr.predict(X_test_pca)
            metrics['mse_PCA'].append(mean_squared_error(Y_test, Y_pred))
            metrics['non_zero_vars_PCA'].append(p)
            
            # PLS
            pls = PLSRegression(n_components=n_components)
            pls.fit(X_train, Y_train)
            Y_pred_pls = pls.predict(X_test)
            metrics['mse_PLS'].append(mean_squared_error(Y_test, Y_pred_pls))
            metrics['non_zero_vars_PLS'].append(p)

            # SPCA using HSIC
            sigma = 0.1
            K = rbf_kernel(Y_train, sigma)
            spca_result = spca_hsic(X_train, Y_train, K, n_components)
            W_hsic = spca_result['W']
            Z_train_hsic = X_train @ W_hsic
            Z_val_hsic = X_val @ W_hsic
            Z_test_hsic = X_test @ W_hsic
            lr_hsic = LinearRegression().fit(Z_train_hsic, Y_train)
            Y_pred_hsic = lr_hsic.predict(Z_test_hsic)
            metrics['mse_HSIC'].append(mean_squared_error(Y_test, Y_pred_hsic))
            metrics['non_zero_vars_HSIC'].append(count_nonzero_vars(W_hsic))

            # Bair's Method
            feature_scores = onp.abs(onp.corrcoef(X_train.T, Y_train.T)[:-1, -1])
            selected_features = feature_scores >= threshold
            X_train_selected = X_train[:, selected_features]
            X_val_selected = X_val[:, selected_features]
            X_test_selected = X_test[:, selected_features]
            pca_bair = PCA(n_components=min(n_components, X_train_selected.shape[1]))
            X_train_bair = pca_bair.fit_transform(X_train_selected)
            X_val_bair = pca_bair.transform(X_val_selected)
            X_test_bair = pca_bair.transform(X_test_selected)
            lr_bair = LinearRegression().fit(X_train_bair, Y_train)
            Y_pred_bair = lr_bair.predict(X_test_bair)
            metrics['mse_Bair'].append(mean_squared_error(Y_test, Y_pred_bair))
            metrics['non_zero_vars_Bair'].append(onp.sum(selected_features))

            # CSPCA
            lambda_grid = [0.01, 0.1, 1]
            best_lambda = lambda_grid[0]
            best_mse = float('inf')
            for lambda_ in lambda_grid:
                spca_sup = cspca(X_train, Y_train, n_components, lambda_=lambda_)
                W_sup = spca_sup['W']
                Z_train_sup = X_train @ W_sup
                Z_val_sup = X_val @ W_sup
                lr_sup = LinearRegression().fit(Z_train_sup, Y_train)
                Y_pred_sup = lr_sup.predict(Z_val_sup)
                current_mse = mean_squared_error(Y_val, Y_pred_sup)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_lambda = lambda_
            
            spca_sup = cspca(X_train, Y_train, n_components, lambda_=best_lambda)
            W_sup = spca_sup['W']
            Z_train_sup = X_train @ W_sup
            Z_test_sup = X_test @ W_sup
            lr_sup = LinearRegression().fit(Z_train_sup, Y_train)
            Y_pred_sup = lr_sup.predict(Z_test_sup)
            metrics['mse_CSPCA'].append(mean_squared_error(Y_test, Y_pred_sup))
            metrics['non_zero_vars_CSPCA'].append(count_nonzero_vars(W_sup))
            
            # SCSPCA
            best_eta_sparse = eta_sparse_grid[0]
            best_mse = float('inf')
            for eta_sparse in eta_sparse_grid:
                kappa = 0.1
                C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
                W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                    C, n_components, p, eta_sparse * onp.ones(p))
                X_train_proj = X_train @ W_manpg
                X_val_proj = X_val @ W_manpg
                reg = LinearRegression()
                reg.fit(X_train_proj, Y_train)
                y_val_pred = reg.predict(X_val_proj)
                current_mse = mean_squared_error(Y_val, y_val_pred)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_sparse = eta_sparse
            
            print(f"Selected eta_sparse: {best_eta_sparse}")
            C = X_train.T @ Y_train @ Y_train.T @ X_train + kappa * X_train.T @ X_train
            W_manpg, F_manpg, sparsity, time_manpg, iter_, flag_succ, num_linesearch, mean_ssn = manpg_orth_sparse(
                C, n_components, p, best_eta_sparse * onp.ones(p))
            X_train_proj = X_train @ W_manpg
            X_test_proj = X_test @ W_manpg
            reg = LinearRegression()
            reg.fit(X_train_proj, Y_train)
            y_test_pred = reg.predict(X_test_proj)
            metrics['mse_SCSPCA'].append(mean_squared_error(Y_test, y_test_pred))
            metrics['non_zero_vars_SCSPCA'].append(count_nonzero_vars(W_manpg))

            # Sparse PLS (SPLS)
            best_eta_spls = eta_spls_grid[0]
            best_mse = float('inf')
            for eta_spls in eta_spls_grid:
                spls_result = spls(X_train, Y_train, K=n_components, 
                                  eta=eta_spls, kappa=0.2, 
                                  scale_x=False, scale_y=False)
                betahat = spls_result['betahat']
                Y_pred_spls = X_val @ betahat
                current_mse = mean_squared_error(Y_val, Y_pred_spls)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_eta_spls = eta_spls
            
            print(f"Selected eta_spls: {best_eta_spls}")
            spls_result = spls(X_train, Y_train, K=n_components, 
                              eta=best_eta_spls, kappa=0.2, 
                              scale_x=False, scale_y=False)
            betahat = spls_result['betahat']
            Y_pred_spls = X_test @ betahat
            W_spls = spls_result['projection']
            if W_spls.shape[1] > n_components:
                W_spls = W_spls[:, :n_components]
            metrics['mse_SPLS'].append(mean_squared_error(Y_test, Y_pred_spls))
            metrics['non_zero_vars_SPLS'].append(count_nonzero_vars(W_spls))

            # Sparse PCA (SPCA)
            best_para_spca = para_spca_grid[0]
            best_mse = float('inf')
            for para_spca in para_spca_grid:
                spca_result = spca(X_train, K=n_components, 
                                 para=para_spca, 
                                 type_="predictor", sparse="penalty", lambda_=1e-4)
                W_spca = spca_result['loadings']
                Z_train_spca = X_train @ W_spca
                Z_val_spca = X_val @ W_spca
                lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
                Y_pred_spca = lr_spca.predict(Z_val_spca)
                current_mse = mean_squared_error(Y_val, Y_pred_spca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_para_spca = para_spca
            
            print(f"Selected para_spca: {best_para_spca}")
            spca_result = spca(X_train, K=n_components, 
                             para=best_para_spca, 
                             type_="predictor", sparse="penalty", lambda_=1e-4)
            W_spca = spca_result['loadings']
            Z_train_spca = X_train @ W_spca
            Z_test_spca = X_test @ W_spca
            lr_spca = LinearRegression().fit(Z_train_spca, Y_train)
            Y_pred_spca = lr_spca.predict(Z_test_spca)
            metrics['mse_SPCA'].append(mean_squared_error(Y_test, Y_pred_spca))
            metrics['non_zero_vars_SPCA'].append(count_nonzero_vars(W_spca))

            # Sparse Supervised PCA
            best_c_sspca = c_sspca_grid[0]
            best_mse = float('inf')
            for c_sspca in c_sspca_grid:
                sspca_result = sspca(X_train, Y_train, K=n_components, c=c_sspca, 
                                   X_test=X_val, Y_test=Y_val, kernel_type='rbf', sigma=0.1)
                Z_train_sspca = sspca_result['Z']
                Z_val_sspca = sspca_result['Z_test']
                reg = LinearRegression().fit(Z_train_sspca, Y_train)
                Y_pred_sspca = reg.predict(Z_val_sspca)
                current_mse = mean_squared_error(Y_val, Y_pred_sspca)
                if current_mse < best_mse:
                    best_mse = current_mse
                    best_c_sspca = c_sspca
            
            print(f"Selected c_sspca: {best_c_sspca}")
            sspca_result = sspca(X_train, Y_train, K=n_components, c=best_c_sspca, 
                               X_test=X_test, Y_test=Y_test, kernel_type='rbf', sigma=0.1)
            Z_train_sspca = sspca_result['Z']
            Z_test_sspca = sspca_result['Z_test']
            W_sspca = sspca_result['V']
            reg = LinearRegression().fit(Z_train_sspca, Y_train)
            Y_pred_sspca = reg.predict(Z_test_sspca)
            metrics['mse_SSPCA'].append(mean_squared_error(Y_test, Y_pred_sspca))
            metrics['non_zero_vars_SSPCA'].append(count_nonzero_vars(W_sspca))
            
        for key in metrics:
            results.loc[i, key] = onp.mean(metrics[key])

    return results

def run_simulation_C(n_datasets=20, n=100, p=500, n_splits=1, n_components_list=[2,3,4]):
    methods = ['PCR', 'PLS', 'HSIC', 'Bair', 'CSPCA', 'SCSPCA', 'SPLS', 'SPCA', 'SSPCA']
    results = {method: {
        'MSE': onp.zeros((n_datasets, len(n_components_list))),
        'NonZeroVars': onp.zeros((n_datasets, len(n_components_list)))
    } for method in methods}

    for i in range(n_datasets):
        onp.random.seed(123 + i)
        cov_matrix = create_toeplitz_cov(p, rho)
        X = onp.random.multivariate_normal(mean=onp.zeros(p), cov=cov_matrix, size=n)
        X_informative = X[:, :4]
        X1 = X_informative[:, 0]
        X2 = X_informative[:, 1]
        X3 = X_informative[:, 2]
        X4 = X_informative[:, 3]
        error = onp.random.normal(0, 0.1, n)
        Y = X1 ** 2 + 3 * onp.sin(X2) - onp.exp(X3 + 1) + 1/(1+X4) + error
        data_C = onp.column_stack((Y[:, onp.newaxis], X))


        res = run_all_methods_analysis(data_C, n_splits=n_splits, n_components_list=n_components_list)

        for method in methods:
            results[method]['MSE'][i] = res[f'mse_{method}']
            results[method]['NonZeroVars'][i] = res[f'non_zero_vars_{method}']
            
    def compute_stats(metric_matrix):
        avg = onp.nanmean(metric_matrix, axis=0)
        std_err = onp.nanstd(metric_matrix, axis=0) / onp.sqrt(n_datasets)
        return {'avg': avg, 'std_err': std_err}

    stats = {method: {
        'MSE': compute_stats(results[method]['MSE']),
        'NonZeroVars': compute_stats(results[method]['NonZeroVars'])
    } for method in methods}

    print("\nSimulation C (Non-Linear: Y = X1^2 + 3sin(X2) - e^(X3 + 1) + 1/(1+X4) + error):")
    for method in methods:
        print(f"  {method}:")
        print("    MSE:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['MSE']['avg'][j]
            se = stats[method]['MSE']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.4f} ± {se:.4f}")
        print("    Non-zero variables:")
        for j, n_comp in enumerate(n_components_list):
            avg = stats[method]['NonZeroVars']['avg'][j]
            se = stats[method]['NonZeroVars']['std_err'][j]
            print(f"      n_components = {n_comp}: Avg = {avg:.1f} ± {se:.1f}")

    return {'stats': stats, 'raw_results': results}

onp.random.seed(219746)
results_C = run_simulation_C(n_datasets=20, n=100, p=500, n_splits=1, n_components_list=[2,3,4])
